<!DOCTYPE html>
<html lang="zh-tw" class="no-js">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Training, Inference, Agents: Beyond Apps in the AI-Native World - NeoTrendHub 會議報告</title>
    <meta name="description" content="AI 驅動的會議報告分析平台">
    <meta name="generator" content="Hugo 0.147.9 - NeoTrendHub">
    <meta name="author" content="NeoTrendHub AI">

    
    <meta property="og:type" content="article">
    <meta property="og:url" content="http://localhost/sessions/session-0a732304/">
    <meta property="og:title" content="Training, Inference, Agents: Beyond Apps in the AI-Native World - NeoTrendHub 會議報告">
    <meta property="og:description" content="AI 驅動的會議報告分析平台">

    
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="http://localhost/sessions/session-0a732304/">
    <meta property="twitter:title" content="Training, Inference, Agents: Beyond Apps in the AI-Native World - NeoTrendHub 會議報告">
    <meta property="twitter:description" content="AI 驅動的會議報告分析平台">

    
    <link rel="stylesheet" href="../../css/styles.css">
    <link rel="preload" href="../../css/styles.css" as="style">

    
    <link rel="canonical" href="http://localhost/sessions/session-0a732304/">
    

    
    <link rel="icon" type="image/x-icon" href="../../favicon.ico">

    
    <meta name="theme-color" content="#3a86ff">
    <meta name="msapplication-TileColor" content="#3a86ff">
</head>
<body class="template-professional hugo-site">
    <div class="container">
        <header class="site-header">
    <nav class="navbar">
        <div class="nav-brand">
            <a href="../../">NeoTrendHub 會議報告</a>
        </div>
        <div class="nav-menu">
            
            <a href="../../" class="nav-link">首頁</a>
            
            <a href="../../seminars/" class="nav-link">研討會</a>
            
            <a href="../../categories/" class="nav-link">分類</a>
            
            <a href="../../tags/" class="nav-link">標籤</a>
            
        </div>
        <div class="nav-toggle">
            <span></span>
            <span></span>
            <span></span>
        </div>
    </nav>
</header>

        <main class="content" id="main-content" role="main">
            
<article class="single-report">
    <header class="report-header section-block meeting-info">
        <h1 class="report-title">Training, Inference, Agents: Beyond Apps in the AI-Native World</h1>
        <div class="report-meta">
            <div class="meta-item">
                <strong>研討會：</strong> 202506 AICon Beijing
            </div>
            <div class="meta-item">
                <strong>類型：</strong> 主題演講
            </div>
            <div class="meta-item">
                <strong>日期：</strong> 2025年07月18日
            </div>
            
        </div>
        
        <div class="report-tags">
            
            <a href="../../tags/%E6%95%B8%E6%93%9A" class="tag">數據</a>
            
            <a href="../../tags/%E9%9B%B2%E7%AB%AF" class="tag">雲端</a>
            
            <a href="../../tags/ai" class="tag">AI</a>
            
            <a href="../../tags/devops" class="tag">DevOps</a>
            
            <a href="../../tags/%E5%BE%8C%E7%AB%AF" class="tag">後端</a>
            
            <a href="../../tags/%E5%AE%89%E5%85%A8" class="tag">安全</a>
            
            <a href="../../tags/%E5%BE%AE%E6%9C%8D%E5%8B%99" class="tag">微服務</a>
            
            <a href="../../tags/202506-aicon-beijing" class="tag">202506 AICon Beijing</a>
            
            <a href="../../tags/%E4%B8%BB%E9%A1%8C%E6%BC%94%E8%AC%9B" class="tag">主題演講</a>
            
        </div>
        
    </header>

    <div class="report-content">
        <h2 id="會議資訊">會議資訊</h2>
<ul>
<li><strong>研討會：</strong> 202506 AICon Beijing</li>
<li><strong>類型：</strong> 主題演講</li>
<li><strong>來源：</strong> <a href="https://aicon.infoq.cn/2025/beijing/presentation/6531">https://aicon.infoq.cn/2025/beijing/presentation/6531</a></li>
</ul>
<hr>
<h2 id="報告內容">報告內容</h2>
<h2 id="訓練推論代理ai原生世界中超越應用程式的發展綜合分析報告">「訓練、推論、代理：AI原生世界中超越應用程式的發展」綜合分析報告</h2>
<h3 id="報告概要">報告概要</h3>
<p>本報告旨在深入分析Mark Collier先生在「202506 AICon Beijing」主題演講《Training, Inference, Agents: Beyond Apps in the AI-Native World》的PPT內容。本次演講聚焦於在「AI原生」（AI-Native）新時代下，人工智能發展的三大核心支柱：訓練（Training）、推論（Inference）和代理（Agents）。報告將從會議概述、技術要點、商業價值、創新亮點以及趨勢洞察等多個維度，為讀者呈現一份全面而深入的分析，旨在闡明開源、基礎設施與社群在AI未來發展中的關鍵作用。</p>
<hr>
<h3 id="1-會議概述和核心內容">1. 會議概述和核心內容</h3>
<p><strong>會議主題與背景：</strong>
本次主題演講《Training, Inference, Agents: Beyond Apps in the AI-Native World》由Linux基金會AI與基礎設施總經理、OpenStack和OpenInfra基金會的共同創辦人Mark Collier先生，於2025年6月在北京的AiCon全球人工智能開發與應用大會上發表。演講的核心思想是，在一個由AI模型主導思考和互動的「AI原生」世界中，AI的發展將超越傳統應用程式的範疇，而其基石在於高效的訓練、推論以及智能代理系統。</p>
<p><strong>核心論點：</strong>
演講者明確指出，AI的蓬勃發展對底層基礎設施提出了前所未有的巨大需求。他強調，AI與基礎設施密不可分，當前AI面臨的最大挑戰之一正是基礎設施層面的瓶頸，如GPU稀缺、高能耗、延遲問題以及數據重力（data gravity）。為了解決這些挑戰並推動AI的開放與普及，開源（Open Source）策略顯得至關重要。DeepSeek等開源模型的異軍突起，已證明了閉源系統的「護城河」是短命的，開源模式將加速創新、促進廣泛採用並增強可訪問性，將價值和創新推向技術堆疊的頂層。</p>
<p>基於此洞察，演講詳細闡述了AI原生計算的三大支柱：</p>
<ol>
<li><strong>訓練 (Training)：</strong> 關於AI模型如何透過數據學習和優化。</li>
<li><strong>推論 (Inference)：</strong> 關於已訓練模型如何進行實時預測和應用。</li>
<li><strong>代理 (Agents)：</strong> 關於AI模型如何被賦予行動能力，並透過協議與工具實現自主決策和協作。</li>
</ol>
<p>貫穿始終的共同主題是：開源生態、健壯的基礎設施以及活躍的社群，是確保AI原生時代開放、互通與繁榮的關鍵要素。演講最終呼籲業界共同投資並建立開放的AI未來。</p>
<hr>
<h3 id="2-技術要點和實現細節">2. 技術要點和實現細節</h3>
<p>本次演講深入探討了AI原生計算的技術棧，以下是其核心技術要點和實現細節：</p>
<p><strong>2.1 AI原生計算的基礎設施要求：</strong></p>
<ul>
<li><strong>數據量與處理能力：</strong> AI對數據的傳輸、儲存與管理提出海量需求，如Google每月處理480兆tokens，比一年前增長50倍。這直接導致對計算能力和儲存帶寬的巨大壓力。</li>
<li><strong>硬體加速器與效率：</strong> GPU稀缺、高能耗和延遲是AI基礎設施面臨的主要挑戰。推論工作負載是訓練的50倍，對效率有極高要求，需要專門的硬體或軟體優化以提高速度和效率。</li>
<li><strong>混合雲/多雲互操作性：</strong> 複雜的環境下，如何確保模型和數據在不同雲平台間的順暢流動與協同作業。</li>
<li><strong>開放基礎設施基石：</strong> 演講強調Linux、OpenStack和Kubernetes等開放基礎設施項目在支撐全球計算生態系統中的核心地位，尤其指出OpenStack在中國的廣泛應用（數百萬計算核心、支援支付寶等）。這些開放平台為AI的發展提供了堅實的底層支援。</li>
</ul>
<p><strong>2.2 AI原生計算的三大支柱及其技術棧：</strong></p>
<ul>
<li>
<p><strong>支柱 ① 訓練 (Training)：</strong></p>
<ul>
<li><strong>定義：</strong> 輸入數據，調整演算法參數，輸出可預測的模型。</li>
<li><strong>核心技術棧：</strong>
<ul>
<li><strong>框架/函式庫：</strong> PyTorch佔據主導地位（80%研究人員使用），TensorFlow和JAX則逐漸被Transformers庫棄用，顯示PyTorch生態的強勢。</li>
<li><strong>基礎設施黏合層：</strong> DeepSpeed、Megatron-LM、Ray等，用於大規模分散式訓練，提高效率和可擴展性。</li>
<li><strong>預訓練檢查點與數據：</strong> DeepSeek-V3、Mistral-7B、RedPajama等開放模型和數據集，加速了模型訓練的迭代和下游創新。</li>
<li><strong>模型相容性與匯出：</strong> ONNX（Open Neural Network Exchange）用於確保不同框架訓練的模型能夠在各種運行時環境中互操作，Hugging Face Transformers則提供了標準化的模型介面和生態。</li>
</ul>
</li>
<li><strong>關鍵要點：</strong> 開放權重和數據集是實現快速迭代和下游創新的關鍵。中立的基金會治理模式（如Linux基金會）在建立信任和推動生態系統發展方面發揮著重要作用。</li>
</ul>
</li>
<li>
<p><strong>支柱 ② 推論 (Inference)：</strong></p>
<ul>
<li><strong>定義：</strong> 載入已訓練模型，接收實時請求，返回預測結果。其可以在從邊緣晶片到資料中心的各種環境中運行。</li>
<li><strong>核心技術棧：</strong>
<ul>
<li><strong>運行時/圖執行：</strong> ONNX Runtime、TensorRT-LLM，負責高效執行模型圖。</li>
<li><strong>分散式引擎：</strong> vLLM已被稱為「事實上的開放生成式AI推論平台」，能夠在各種硬體和雲環境中連接多種LLM，並透過OpenStack整合。其他如abrix和LLM-d也在此領域發展。</li>
<li><strong>服務框架：</strong> KServe、Triton Inference Server，用於標準化模型服務部署在Kubernetes/OpenStack上。</li>
<li><strong>優化/快取：</strong> LM Cache等技術，提高推論效率。</li>
</ul>
</li>
<li><strong>核心概念：LLM作為新作業系統。</strong> 演講借鑒Andrej Karpathy的「軟體3.0」概念，將LLM比作新一代作業系統：
<ul>
<li><strong>核心（Kernel）</strong> → 推論運行時（ONNX Runtime, vLLM, LLM-d），負責調度tokens。</li>
<li><strong>系統呼叫（Syscalls）</strong> → 代理協議（MCP, A2A），標準化函數呼叫、生成代理等。</li>
<li><strong>使用者空間應用（User-land apps）</strong> → 代理工作流程（LangChain, CrewAI, Autogen）。</li>
<li><strong>週邊設備（Peripherals）</strong> → 工具/技能（插件、解釋器、資料庫）。</li>
</ul>
</li>
<li><strong>關鍵要點：</strong> 推論是AI產品化和商業化的核心，其效率和可靠性至關重要。LLM-d作為基於Kubernetes的大規模分散式推論項目，若成功，可能成為「AI的核心」。多加速器調度抽象是未來發展的關鍵。</li>
</ul>
</li>
<li>
<p><strong>支柱 ③ 代理 (Agents)：</strong></p>
<ul>
<li><strong>定義：</strong> 將模型封裝在程式碼中，使其能夠呼叫工具、與其他代理或人類對話，並透過開放協議（如MCP）將推論結果轉化為行動。</li>
<li><strong>核心技術棧：</strong>
<ul>
<li><strong>協議與標準：</strong> MCP（Model Communication Protocol）和A2A（Agent2Agent Protocol）是實現代理間互操作的關鍵。Google Cloud將A2A轉移到Linux基金會，並有多家科技巨頭（Amazon、Cisco、Google、Microsoft等）參與，顯示其標準化和開放治理的重要性。</li>
<li><strong>代理框架：</strong> LangChain、CrewAI、IDEA、ChatDev，提供構建代理工作流程的工具和抽象。</li>
<li><strong>工具註冊中心/API：</strong> OpenAI Function Calling、BentoML Tool Hub，使代理能夠發現和使用外部工具。</li>
<li><strong>底層基礎設施：</strong> 技能/工具插件（API管理、企業資源）、記憶體/向量儲存（Chroma, Weaviate, pgvector, Redis-Vector）是代理運行的關鍵支援。</li>
</ul>
</li>
<li><strong>核心概念：情境工程（Context Engineering）與代理速度。</strong> 軟體焦點從「使用者速度」轉向「代理速度」，即不再僅限於人類鍵盤輸入的速度，而是代理池的無限吞吐量。與此同時，「情境工程」（將正確資訊填入代理上下文）的重要性遠超「提示工程」。</li>
<li><strong>關鍵要點：</strong> 代理仍處早期階段，但潛力巨大。標準協議是避免供應商鎖定和實現互通性的基石。小型語言模型（SLM）因其效率和適用性，被視為代理式AI的未來。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="3-商業價值和應用場景">3. 商業價值和應用場景</h3>
<p>AI原生世界的三大支柱不僅帶來技術上的進步，更孕育著巨大的商業價值和廣泛的應用場景。</p>
<ul>
<li>
<p><strong>自動化與效率提升：</strong></p>
<ul>
<li><strong>軟體自行編寫：</strong> 微軟、Google、Meta等科技巨頭已證實AI能自動生成高達30%-50%的程式碼。這將極大地提高開發效率，縮短產品上市時間，並降低開發成本。</li>
<li><strong>代理自動化工作流程：</strong> AI代理能夠自動化重複性工作（如程式碼生成、文件處理、運營操作），將人類從繁瑣任務中解放出來，專注於規劃、審查和協調等高階任務，從根本上重塑企業的營運模式。</li>
<li><strong>推論效率優化：</strong> 推論作為AI工作負載的絕大部分（50倍於訓練），其效率的提升直接關係到AI產品的商業可行性和成本效益。高效的推論平台如vLLM能顯著降低企業運行AI服務的TCO（總擁有成本），使得AI規模化應用成為可能。</li>
</ul>
</li>
<li>
<p><strong>市場顛覆與新商機：</strong></p>
<ul>
<li><strong>開源的市場衝擊：</strong> DeepSeek等開源模型的崛起，導致Nvidia股價下跌，並揭示了「大型語言模型之間沒有護城河」的市場現實。這意味著AI模型不再是少數巨頭的專利，中小企業和新創公司可透過開源模型快速切入市場，激發更廣泛的創新和競爭。</li>
<li><strong>價值鏈的重塑：</strong> 開源軟體（OSS）透過降低雲平台、軟體、硬體和服務的底層成本，將價值和創新推向了技術堆疊的頂層，例如基礎模型、微調專業模型、模型中心和AI安全等。這為企業在這些高附加值領域創造了新的商業機會。</li>
<li><strong>AI作為服務（AIaaS）：</strong> 標準化的推論服務框架（KServe, Triton）和代理協議（A2A）使得AI能力可以更便捷地作為服務被整合和消費，催生更多基於AI的垂直行業解決方案和創新應用。</li>
</ul>
</li>
<li>
<p><strong>行業應用廣度：</strong></p>
<ul>
<li><strong>企業級應用：</strong> OpenStack在中國金融（支付寶）、電信（中國移動、電信、聯通）、能源（國家電網）等關鍵基礎設施中的應用，證明了開放基礎設施在承載核心業務方面的成熟度。AI的加入將使這些傳統行業實現更深度的智能轉型。</li>
<li><strong>新興AI應用：</strong> 自動駕駛（BMW, Hyundai, Volvo）、智能硬件、具身智能、金融+大模型、多模態大模型、LMOps等，都是未來AI的重要應用場景，預計將深度整合AI原生計算的三大支柱。</li>
<li><strong>軟體產品設計的轉變：</strong> 從以人類使用者為中心的設計轉變為以AI代理為中心的設計，產品使用者體驗將更多地優化於「規劃、審查和協調」等，這將催生全新的軟體產品形態和服務模式。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="4-創新亮點和技術突破">4. 創新亮點和技術突破</h3>
<p>本次演講所呈現的內容，不僅是對AI發展現狀的歸納，更揭示了多個前瞻性的創新亮點和潛在的技術突破：</p>
<ul>
<li>
<p><strong>AI模型性能的開源超越：</strong></p>
<ul>
<li>最引人注目的創新之一是開源AI模型（如DeepSeek R1）在評估指標上已「大體趕上甚至超越閉源AI模型」。這顛覆了過去專有模型主導的局面，證實了開源社群的力量和快速迭代能力。DeepSeek R1在Hugging Face上數週內破千萬下載量，證明了開源模式在創新傳播和廣泛採用方面的巨大優勢。</li>
</ul>
</li>
<li>
<p><strong>「LLM作為新作業系統」的範式轉移：</strong></p>
<ul>
<li>Andrej Karpathy的「軟體3.0」概念被引申為「LLM作為新作業系統」的思考，這是一個極具突破性的創新觀點。它將AI推論運行時視為系統核心，代理協議為系統呼叫，代理工作流程為使用者空間應用，工具為週邊設備。這種視角不僅重新定義了程式設計和系統互動方式，更預示著一個以模型為中心、而非傳統程式碼為中心的全新計算範式，可能從根本上改變軟體的設計、開發和部署。</li>
</ul>
</li>
<li>
<p><strong>情境工程（Context Engineering）的崛起：</strong></p>
<ul>
<li>演講強調「情境工程」的重要性遠超傳統的「提示工程」。這是一項新的關鍵技能，旨在藝術與科學地將正確的資訊填充到AI模型的上下文視窗中，以實現代理的準確性和效率。這項創新直接影響到代理的性能和成本，是實現複雜、可靠AI代理的基石。</li>
</ul>
</li>
<li>
<p><strong>AI代理標準協議的里程碑式發展：</strong></p>
<ul>
<li>MCP（Model Communication Protocol）和A2A（Agent2Agent Protocol）的提出與發展，特別是Google Cloud將A2A項目移交給Linux基金會，並獲得Amazon、Cisco、Microsoft等巨頭的共同參與，標誌著AI代理互操作性標準化的重大突破。這將為未來AI代理生態系統的開放、互通和健康發展奠定基礎，避免供應商鎖定，並促進跨平台、跨代理的協作。</li>
</ul>
</li>
<li>
<p><strong>小型語言模型（SLM）在代理式AI中的潛力：</strong></p>
<ul>
<li>NVIDIA和Georgia Tech研究人員提出的「小型語言模型是代理式AI的未來」的觀點，指出了SLM在代理系統中的獨特優勢：足夠強大、更適合、更經濟。這項洞察將推動針對特定任務和效率需求，開發和部署更輕量、更高效的AI模型，實現更廣泛的邊緣AI和嵌入式AI代理應用。</li>
</ul>
</li>
<li>
<p><strong>AI原生計算技術堆疊的整合與成熟：</strong></p>
<ul>
<li>圍繞PyTorch、ONNX、Transformers、DeepSpeed、Ray等形成的新訓練堆疊，以及以vLLM為事實標準、LLM-d為潛在核心的推論堆疊，正在快速成熟。這些開源項目的協同發展，使得大規模AI模型訓練和推論的效率和可擴展性得以顯著提升，為AI原生應用的普及提供了堅實的技術底座。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="5-趨勢洞察和未來展望">5. 趨勢洞察和未來展望</h3>
<p>本次演講不僅是對當前AI技術的梳理，更是對未來AI發展趨勢的深刻洞察和預測，為業界勾勒出AI原生世界的宏偉藍圖。</p>
<p><strong>5.1 計算範式的演進：從雲到AI原生</strong>
演講透過「歷史重演」的類比，明確指出計算領域正經歷從「雲計算」（VMs + OpenStack）到「雲原生計算」（Containers + Kubernetes），再到「AI原生計算」（Tokens + AI-Native Stack）的演進。這是一個質的飛躍，意味著：</p>
<ul>
<li><strong>核心單位的轉變：</strong> 從傳統的虛擬機和容器，轉變為以「tokens」為核心的AI模型交互單位。</li>
<li><strong>基礎設施的重塑：</strong> 未來的基礎設施將不再僅僅優化數據儲存或容器編排，而是專為運行持續學習系統、處理tokens串流和代理工作流程、以及大規模優化推論而設計。這將帶來對硬體、軟體和網絡架構的全新要求。</li>
<li><strong>軟體開發的革命：</strong> AI將「自行編寫軟體」，人類開發者的角色將從編寫程式碼轉向更高層次的「規劃、審查和協調」。這將徹底顛覆傳統軟體工程範式。</li>
</ul>
<p><strong>5.2 開源與開放生態的必然趨勢</strong>
演講者強烈主張「開源站在歷史的正確一邊」，並指出閉源的「護城河」是短命的。這一判斷基於以下事實和預期：</p>
<ul>
<li><strong>性能追趕與超越：</strong> 開源AI模型已證明其在性能上可與閉源模型抗衡甚至超越。</li>
<li><strong>加速創新與採用：</strong> 開源模式透過開放權重、開放數據集和社群協作，極大地加速了技術迭代和市場採用，形成了強大的飛輪效應。</li>
<li><strong>避免供應商鎖定：</strong> 透過開放協議和標準（如A2A納入Linux基金會），確保AI生態系統的互操作性，避免單一供應商的壟斷，保障企業和開發者的自由選擇權。</li>
<li><strong>集體投資與社群力量：</strong> 構建開放平台需要巨大的集體投資，過去OpenStack和Kubernetes等開放雲平台獲得了數億美元的投入，而AI原生時代預計需要接近10億美元的投資。社群被視為實現這一目標的「重心」，透過「四開放原則」（開源、開放設計、開放開發、開放社群）來確保生態系統的健康發展。</li>
</ul>
<p><strong>5.3 AI代理：未來軟體的形態</strong>
AI代理被視為未來軟體開發和應用的核心趨勢：</p>
<ul>
<li><strong>軟體焦點轉移：</strong> 從「使用者速度」轉向「代理速度」，意味著軟體將為AI代理的無限吞吐量和高效率設計，而非僅限於人類輸入的速度。</li>
<li><strong>情境工程的重要性：</strong> 這項新興技能將成為設計和優化AI代理的關鍵，影響代理的效率、成本和可靠性。</li>
<li><strong>小型語言模型的戰略地位：</strong> SLM因其輕量、高效和成本效益，將在代理式AI中扮演越來越重要的角色，尤其在邊緣計算和特定領域應用中。</li>
</ul>
<p><strong>5.4 基礎設施的持續挑戰與機遇</strong>
儘管AI發展迅猛，基礎設施瓶頸仍是核心挑戰。這也意味著巨大的投資和創新機遇：</p>
<ul>
<li><strong>多加速器調度：</strong> 隨著不同硬體加速器（GPU、TPU、FPGA等）的發展，如何高效調度這些異構資源將是關鍵。</li>
<li><strong>效率為王：</strong> 對於推論工作負載，追求極致的效率是永恆的主題，將驅動更多優化、快取和分散式技術的突破。</li>
<li><strong>整合的挑戰與社群的需求：</strong> 簡報承認當前AI技術棧整合難度高，呼籲一個強大的社群來協調這些新興技術，形成統一、易用的平台。</li>
</ul>
<p><strong>5.5 展望與呼籲</strong>
演講最終發出強烈呼籲：「讓我們共同建立開放的AI未來！」這不僅是技術上的願景，更是一種協作精神的號召。預計未來將有更多像AI_DEV峰會這樣的平台，推動業界在開放治理、標準制定和社群建設方面加大投入，共同塑造AI原生時代的樣貌。確保AI原生時代是開放的，將是避免重蹈雲計算時代「閉源鎖定」覆轍的關鍵。</p>
<hr>
<h3 id="總結">總結</h3>
<p>Mark Collier先生的演講清晰地勾勒出AI原生世界的宏大圖景。它不僅定義了訓練、推論和代理這三大核心支柱，更深刻地闡釋了開源、基礎設施與社群在這一轉型中的決定性作用。AI的爆發式增長對現有基礎設施提出了嚴峻考驗，而開源模式的勝利已成為不可逆轉的趨勢，它不僅加速了創新，也為市場帶來顛覆性的變革。LLM作為新作業系統的思考，以及AI代理標準協議的成熟，都預示著軟體範式將發生根本性轉變。</p>
<p>展望未來，計算的核心將從應用程式轉向AI模型，從人類交互轉向代理協作。這需要業界巨大的集體投資，更需要一個強大、開放的社群作為「重心」，協調技術發展、制定標準、建立信任。正如Linux和Kubernetes開啟了開放的雲時代，開放的社群也將是確保AI原生時代真正開放、創新和繁榮的唯一途徑。這場變革既帶來挑戰，更帶來了前所未有的機遇，一個由開放、智能和協作驅動的未來正加速到來。</p>
<hr>
<div style="text-align: center; color: #666; font-size: 0.9em; margin-top: 2em;">
<em>本報告由 NeoTrendHub 自動生成 | 生成時間：2025-07-18 14:11:29</em>
</div>

    </div>

    <footer class="report-footer section-block">
        <div class="report-navigation">
            
            <a href="http://localhost/sessions/session-188a161a/" class="nav-link prev">
                <span class="nav-label">上一篇</span>
                <span class="nav-title">一年上线超 10 款产品，AI 时代如何做独立开发</span>
            </a>
            

            
            <a href="http://localhost/sessions/session-d9f22387/" class="nav-link next">
                <span class="nav-label">下一篇</span>
                <span class="nav-title">SGLang 推理引擎——高效的开源部署方案</span>
            </a>
            
        </div>

        <div class="report-info">
            <p><em>本報告由 NeoTrendHub 自動生成 | 生成時間：2025-07-18 00:00:00</em></p>
        </div>
    </footer>
</article>

        </main>

        <footer class="site-footer">
    <div class="footer-content">
        <div class="footer-info">
            <p>&copy; 2025 NeoTrendHub 會議報告. 由 NeoTrendHub 驅動。</p>
            <p>AI 驅動的會議報告分析平台</p>
        </div>
        <div class="footer-links">
            <a href="../../">首頁</a>
            <a href="../../seminars/">研討會</a>
            <a href="../../categories/">分類</a>
            <a href="../../tags/">標籤</a>
        </div>
    </div>
</footer>
    </div>

    
    <script src="../../js/main.js" defer></script>

    
    <script>document.documentElement.classList.remove('no-js');</script>
</body>
</html>